{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Struct2Seq from Scratch\n",
    "\n",
    "This notebook walks through every step required to construct, train, evaluate, and sample from the Struct2Seq model using only the reusable modules provided in this repository. Rather than relying on the pre-written training script, we assemble the full pipeline manually to illustrate how each component fits together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "We begin by importing core libraries, enabling deterministic behavior, and configuring the compute device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from struct2seq import data as s2s_data\n",
    "from struct2seq import struct2seq as s2s_model\n",
    "from struct2seq import noam_opt\n",
    "from experiments import utils as exp_utils\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')\n",
    "\n",
    "def set_seed(seed: int = 7):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "`StructureDataset` expects a JSONL file where each line contains the amino acid sequence and 3D coordinates for a single protein chain. If you do not have the NeurIPS 2019 dataset locally, point `dataset_path` to your own JSONL file produced with `data/build_chain_dataset.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSONL dataset. Replace this with a real file before running.\n",
    "dataset_path = Path('data/SPIN2/train.jsonl')\n",
    "assert dataset_path.exists(), (\"Dataset not found. Please set 'dataset_path' to your JSONL file.\")\n",
    "\n",
    "full_dataset = s2s_data.StructureDataset(str(dataset_path))\n",
    "print(f'Total chains available: {len(full_dataset)}')\n",
    "print('Example entry keys:', full_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation Split\n",
    "\n",
    "For reproducibility we perform a simple split. The built-in dataset already provides length-aware batching through `StructureLoader`, which keeps sequences of similar length together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.9 * len(full_dataset))\n",
    "train_indices = np.arange(num_train)\n",
    "valid_indices = np.arange(num_train, len(full_dataset))\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "valid_dataset = Subset(full_dataset, valid_indices)\n",
    "\n",
    "batch_tokens = 2000  # approximate number of amino acids per batch\n",
    "train_loader = s2s_data.StructureLoader(train_dataset, batch_tokens=batch_tokens, shuffle=True)\n",
    "valid_loader = s2s_data.StructureLoader(valid_dataset, batch_tokens=batch_tokens, shuffle=False)\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}, Validation batches: {len(valid_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Featurization\n",
    "\n",
    "`experiments.utils.featurize` pads variable-length chains and assembles the coordinate tensor `(X)`, amino acid indices `(S)`, valid-mask, and chain lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(loader):\n",
    "    for batch in loader:\n",
    "        X, S, mask, lengths = exp_utils.featurize(batch, device=DEVICE)\n",
    "        yield X, S, mask, lengths\n",
    "\n",
    "example_X, example_S, example_mask, example_lengths = next(next_batch(train_loader))\n",
    "print('Coordinate tensor:', example_X.shape)\n",
    "print('Sequence tensor:', example_S.shape)\n",
    "print('Mask tensor:', example_mask.shape)\n",
    "print('Lengths:', example_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Construction\n",
    "\n",
    "We instantiate `Struct2Seq` by specifying the feature sizes, number of attention layers, neighborhood size, and other architectural details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "model = s2s_model.Struct2Seq(\n",
    "    num_letters=20,\n",
    "    node_features=hidden_dim,\n",
    "    edge_features=hidden_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    k_neighbors=30,\n",
    "    protein_features='full',\n",
    "    dropout=0.1,\n",
    "    augment_eps=0.0,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    forward_attention_decoder=True,\n",
    "    use_mpnn=False\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model)\n",
    "print(f'Total parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Function and Optimizer\n",
    "\n",
    "Struct2Seq outputs log-probabilities over amino acid types. We therefore use negative log-likelihood with optional label smoothing. The `NoamOpt` wrapper reproduces the learning-rate schedule from the original Transformer paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = noam_opt.get_std_opt(model.parameters(), hidden_dim, factor=1.0, warmup=4000)\n",
    "label_smoothing = 0.1\n",
    "\n",
    "def compute_loss(S_true, log_probs, mask):\n",
    "    loss, loss_av = exp_utils.loss_smoothed(S_true, log_probs, mask, weight=label_smoothing)\n",
    "    return loss, loss_av\n",
    "\n",
    "# quick sanity check\n",
    "with torch.no_grad():\n",
    "    log_probs = model(example_X, example_S, example_lengths, example_mask)\n",
    "    _, example_loss = compute_loss(example_S, log_probs, example_mask)\n",
    "print(f'Initial loss (random weights): {example_loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "\n",
    "Below is a minimalist training loop. Adjust `num_epochs`, gradient clipping, and mixed precision as needed. To keep the notebook lightweight, you may reduce the number of steps or batches when experimenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "training"
    ]
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "log_every = 10\n",
    "\n",
    "def run_epoch(loader, model, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    for step, batch in enumerate(loader, start=1):\n",
    "        X, S, mask, lengths = exp_utils.featurize(batch, device=DEVICE)\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "        log_probs = model(X, S, lengths, mask)\n",
    "        loss, loss_av = compute_loss(S, log_probs, mask)\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        tokens = mask.sum().item()\n",
    "        total_loss += loss_av.item() * tokens\n",
    "        total_tokens += tokens\n",
    "        if is_train and step % log_every == 0:\n",
    "            print(f'[train] step={step} loss={loss_av.item():.3f}')\n",
    "    return total_loss / max(total_tokens, 1)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = run_epoch(train_loader, model, optimizer)\n",
    "    with torch.no_grad():\n",
    "        valid_loss = run_epoch(valid_loader, model, optimizer=None)\n",
    "    print(f'Epoch {epoch:02d}: train NLL={train_loss:.4f}, valid NLL={valid_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics\n",
    "\n",
    "Besides negative log-likelihood, we can compute accuracy or perplexity. This cell illustrates a masked accuracy computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            X, S, mask, lengths = exp_utils.featurize(batch, device=DEVICE)\n",
    "            log_probs = model(X, S, lengths, mask)\n",
    "            preds = log_probs.argmax(dim=-1)\n",
    "            correct += ((preds == S) * mask).sum().item()\n",
    "            total += mask.sum().item()\n",
    "    return correct / max(total, 1)\n",
    "\n",
    "val_accuracy = evaluate_accuracy(valid_loader, model)\n",
    "print(f'Validation accuracy: {val_accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Autoregressive Sampling\n",
    "\n",
    "After training, we can generate sequences conditioned on the backbone coordinates. The sampler predicts one residue at a time using the autoregressive decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMINO_ACIDS = np.array(list(exp_utils.AMINO_ACIDS))\n",
    "\n",
    "def sample_sequences(loader, model, temperature=1.0):\n",
    "    model.eval()\n",
    "    sequences = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            X, _, mask, lengths = exp_utils.featurize(batch, device=DEVICE)\n",
    "            sampled = model.sample(X, lengths, mask, temperature=temperature)\n",
    "            sampled = sampled.cpu().numpy()\n",
    "            for seq_arr, seq_mask in zip(sampled, mask.cpu().numpy()):\n",
    "                length = int(seq_mask.sum())\n",
    "                sequences.append(''.join(AMINO_ACIDS[seq_arr[:length]]))\n",
    "    return sequences\n",
    "\n",
    "generated_sequences = sample_sequences(valid_loader, model, temperature=1.0)\n",
    "print('\n'.join(generated_sequences[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Checkpointing\n",
    "\n",
    "Finally, save the trained parameters to disk for later reuse. The `experiments.utils` module already contains helper routines for restoring checkpoints if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path('struct2seq_from_scratch.pt')\n",
    "torch.save({'model_state_dict': model.state_dict()}, checkpoint_path)\n",
    "print(f'Saved checkpoint to {checkpoint_path.resolve()}')\n",
    "\n",
    "# Example of loading the checkpoint back\n",
    "state = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "print('Checkpoint restored successfully.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
