{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Struct2Seq with PyTorch Geometric Tutorial\n",
    "\n",
    "This notebook demonstrates the refactored Struct2Seq model using PyTorch Geometric.\n",
    "\n",
    "**Struct2Seq** is a graph neural network model for protein sequence design. Given a protein backbone structure (3D coordinates), it generates amino acid sequences that are likely to fold into that structure.\n",
    "\n",
    "## What's New in This Refactored Version?\n",
    "\n",
    "1. **PyTorch Geometric Integration**: Uses PyG's efficient graph operations and batching\n",
    "2. **Cleaner Architecture**: Modular design with separate files for data, features, layers, and models\n",
    "3. **Better Documentation**: Clear docstrings and comments throughout\n",
    "4. **Modern Practices**: Uses PyG's `MessagePassing` API for custom GNN layers\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Understanding the Data Format](#data-format)\n",
    "3. [Creating Protein Graphs](#protein-graphs)\n",
    "4. [Model Architecture](#model-architecture)\n",
    "5. [Training the Model](#training)\n",
    "6. [Sampling Sequences](#sampling)\n",
    "7. [Evaluation](#evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import our refactored modules\n",
    "from struct2seq_pyg import (\n",
    "    ProteinGraphDataset,\n",
    "    create_protein_graph,\n",
    "    Struct2SeqPyG,\n",
    "    ProteinFeaturizer\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the Data Format <a name=\"data-format\"></a>\n",
    "\n",
    "Protein structures are stored in JSONL format with the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"protein_id\",\n",
    "    \"seq\": \"ACDEFGH...\",\n",
    "    \"coords\": {\n",
    "        \"N\": [[x, y, z], ...],\n",
    "        \"CA\": [[x, y, z], ...],\n",
    "        \"C\": [[x, y, z], ...],\n",
    "        \"O\": [[x, y, z], ...]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Each protein has:\n",
    "- `name`: Unique identifier\n",
    "- `seq`: Amino acid sequence (single-letter codes)\n",
    "- `coords`: 3D coordinates for backbone atoms (N, CA, C, O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a synthetic protein for demonstration\n",
    "# In practice, you would load real data from a JSONL file\n",
    "\n",
    "def create_example_protein():\n",
    "    \"\"\"Create a small synthetic protein for demonstration.\"\"\"\n",
    "    length = 10\n",
    "    \n",
    "    # Simple linear backbone\n",
    "    coords = {\n",
    "        'N': np.random.randn(length, 3),\n",
    "        'CA': np.random.randn(length, 3),\n",
    "        'C': np.random.randn(length, 3),\n",
    "        'O': np.random.randn(length, 3),\n",
    "    }\n",
    "    \n",
    "    # Random sequence\n",
    "    AA_ALPHABET = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    sequence = ''.join(np.random.choice(list(AA_ALPHABET), length))\n",
    "    \n",
    "    return coords, sequence\n",
    "\n",
    "coords, sequence = create_example_protein()\n",
    "print(f\"Example sequence: {sequence}\")\n",
    "print(f\"Sequence length: {len(sequence)}\")\n",
    "print(f\"CA coordinates shape: {coords['CA'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Protein Graphs <a name=\"protein-graphs\"></a>\n",
    "\n",
    "We convert protein structures into graphs where:\n",
    "- **Nodes** represent residues (amino acids)\n",
    "- **Edges** connect k-nearest neighbor residues in 3D space\n",
    "- **Node features** encode backbone geometry (dihedral angles)\n",
    "- **Edge features** encode pairwise relationships (distance, orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a protein graph\n",
    "featurizer = ProteinFeaturizer()\n",
    "data = create_protein_graph(\n",
    "    coords=coords,\n",
    "    sequence=sequence,\n",
    "    k_neighbors=5,  # Use 5 nearest neighbors (normally 30)\n",
    "    featurizer=featurizer\n",
    ")\n",
    "\n",
    "print(\"\\nProtein Graph:\")\n",
    "print(f\"  Number of nodes: {data.num_nodes}\")\n",
    "print(f\"  Number of edges: {data.edge_index.size(1)}\")\n",
    "print(f\"  Node features shape: {data.x.shape}\")\n",
    "print(f\"  Edge features shape: {data.edge_attr.shape}\")\n",
    "print(f\"  Sequence shape: {data.seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph structure\n",
    "def visualize_protein_graph(data, max_nodes=50):\n",
    "    \"\"\"Visualize the graph connectivity as an adjacency matrix.\"\"\"\n",
    "    num_nodes = min(data.num_nodes, max_nodes)\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    edge_index = data.edge_index[:, data.edge_index[0] < num_nodes]\n",
    "    edge_index = edge_index[:, edge_index[1] < num_nodes]\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(adj.numpy(), cmap='Blues', interpolation='nearest')\n",
    "    plt.colorbar(label='Edge')\n",
    "    plt.xlabel('Residue Index')\n",
    "    plt.ylabel('Residue Index')\n",
    "    plt.title('k-NN Graph Structure')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_protein_graph(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture <a name=\"model-architecture\"></a>\n",
    "\n",
    "The Struct2Seq model has an encoder-decoder architecture:\n",
    "\n",
    "### Encoder (Structure Processing)\n",
    "- Takes protein backbone structure as input\n",
    "- Uses graph attention layers (unmasked)\n",
    "- Learns structural representations\n",
    "\n",
    "### Decoder (Sequence Generation)\n",
    "- Generates amino acid sequence autoregressively\n",
    "- Uses masked graph attention (only attends to past positions)\n",
    "- Conditioned on structure encoding\n",
    "\n",
    "### Features\n",
    "- Multi-head attention over k-NN neighbors\n",
    "- Rich edge features (positional encodings, RBF distances, orientations)\n",
    "- Layer normalization and residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Struct2SeqPyG(\n",
    "    node_feature_dim=6,      # Dihedral angles (phi, psi, omega) as sin/cos\n",
    "    edge_feature_dim=39,     # Positional encodings (16) + RBF (16) + Orientations (7)\n",
    "    hidden_dim=128,          # Hidden dimension\n",
    "    num_encoder_layers=3,    # Number of encoder layers\n",
    "    num_decoder_layers=3,    # Number of decoder layers\n",
    "    num_letters=20,          # 20 amino acids\n",
    "    num_heads=4,             # Attention heads\n",
    "    dropout=0.1,             # Dropout probability\n",
    "    use_mpnn=False           # Use GAT instead of MPNN\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nModel has {num_params:,} parameters\")\n",
    "\n",
    "# Show model structure\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Model <a name=\"training\"></a>\n",
    "\n",
    "Training uses teacher forcing:\n",
    "1. Feed the structure and ground-truth sequence to the model\n",
    "2. Model predicts amino acids at each position\n",
    "3. Compute cross-entropy loss with ground truth\n",
    "4. Backpropagate and update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        log_probs = model(batch)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.nll_loss(log_probs, batch.seq)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        log_probs = model(batch)\n",
    "        \n",
    "        # Compute metrics\n",
    "        loss = F.nll_loss(log_probs, batch.seq)\n",
    "        pred = log_probs.argmax(dim=-1)\n",
    "        correct = (pred == batch.seq).sum().item()\n",
    "        \n",
    "        total_loss += loss.item() * batch.num_nodes\n",
    "        total_correct += correct\n",
    "        total_samples += batch.num_nodes\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "    perplexity = np.exp(avg_loss)\n",
    "    \n",
    "    return avg_loss, accuracy, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training loop (with synthetic data)\n",
    "# In practice, you would use a real dataset\n",
    "\n",
    "def create_synthetic_dataset(num_proteins=100, length_range=(20, 100)):\n",
    "    \"\"\"Create a synthetic dataset for demonstration.\"\"\"\n",
    "    data_list = []\n",
    "    AA_ALPHABET = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    \n",
    "    for i in range(num_proteins):\n",
    "        length = np.random.randint(*length_range)\n",
    "        \n",
    "        # Create random coordinates\n",
    "        coords = {\n",
    "            'N': np.random.randn(length, 3),\n",
    "            'CA': np.random.randn(length, 3),\n",
    "            'C': np.random.randn(length, 3),\n",
    "            'O': np.random.randn(length, 3),\n",
    "        }\n",
    "        \n",
    "        # Random sequence\n",
    "        sequence = ''.join(np.random.choice(list(AA_ALPHABET), length))\n",
    "        \n",
    "        # Create graph\n",
    "        data = create_protein_graph(coords, sequence, k_neighbors=10)\n",
    "        data_list.append(data)\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "# Create synthetic datasets\n",
    "train_data = create_synthetic_dataset(100)\n",
    "val_data = create_synthetic_dataset(20)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=4, shuffle=False)\n",
    "\n",
    "print(f\"Training set: {len(train_data)} proteins\")\n",
    "print(f\"Validation set: {len(val_data)} proteins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_perplexity = evaluate(model, val_loader, device)\n",
    "    \n",
    "    # Record metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"  Val Perplexity: {val_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(val_accuracies, label='Val Accuracy', color='green')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sampling Sequences <a name=\"sampling\"></a>\n",
    "\n",
    "Once trained, the model can generate novel sequences for a given structure using autoregressive sampling:\n",
    "1. Start with empty sequence\n",
    "2. At each position, predict amino acid distribution\n",
    "3. Sample from the distribution\n",
    "4. Add sampled amino acid and continue\n",
    "\n",
    "Temperature controls randomness:\n",
    "- **Low temperature** (0.1): More deterministic, picks most likely amino acids\n",
    "- **High temperature** (1.0+): More random, explores diverse sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sequences for a test protein\n",
    "test_protein = val_data[0].to(device)\n",
    "AA_ALPHABET = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "\n",
    "# Sample with different temperatures\n",
    "temperatures = [0.1, 0.5, 1.0]\n",
    "\n",
    "print(\"Sampling sequences with different temperatures:\\n\")\n",
    "\n",
    "for temp in temperatures:\n",
    "    sampled_seq = model.sample(test_protein, temperature=temp)\n",
    "    sampled_seq_str = ''.join([AA_ALPHABET[i] for i in sampled_seq[0].cpu().numpy()])\n",
    "    \n",
    "    print(f\"Temperature {temp}:\")\n",
    "    print(f\"  {sampled_seq_str}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze amino acid composition\n",
    "def plot_aa_composition(sequences, title=\"Amino Acid Composition\"):\n",
    "    \"\"\"Plot amino acid composition of sequences.\"\"\"\n",
    "    AA_ALPHABET = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    \n",
    "    # Count amino acids\n",
    "    counts = {aa: 0 for aa in AA_ALPHABET}\n",
    "    total = 0\n",
    "    \n",
    "    for seq in sequences:\n",
    "        for aa_idx in seq:\n",
    "            aa = AA_ALPHABET[aa_idx]\n",
    "            counts[aa] += 1\n",
    "            total += 1\n",
    "    \n",
    "    # Convert to frequencies\n",
    "    freqs = {aa: counts[aa] / total for aa in AA_ALPHABET}\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(freqs.keys(), freqs.values())\n",
    "    plt.xlabel('Amino Acid')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Sample multiple sequences and analyze composition\n",
    "sampled_sequences = []\n",
    "for _ in range(10):\n",
    "    seq = model.sample(test_protein, temperature=1.0)\n",
    "    sampled_sequences.append(seq[0].cpu())\n",
    "\n",
    "plot_aa_composition(sampled_sequences, \"Sampled Sequences - AA Composition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation <a name=\"evaluation\"></a>\n",
    "\n",
    "We evaluate the model using:\n",
    "- **Perplexity**: Lower is better, measures how well the model predicts sequences\n",
    "- **Recovery**: Percentage of native amino acids recovered when redesigning\n",
    "- **Amino acid composition**: Should match natural protein statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute recovery rate (native sequence recovery)\n",
    "@torch.no_grad()\n",
    "def compute_recovery(model, data, num_samples=10):\n",
    "    \"\"\"Compute sequence recovery rate.\"\"\"\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    \n",
    "    # Ground truth sequence\n",
    "    true_seq = data.seq.cpu().numpy()\n",
    "    \n",
    "    # Sample sequences\n",
    "    recoveries = []\n",
    "    for _ in range(num_samples):\n",
    "        sampled = model.sample(data, temperature=0.1)  # Low temp for deterministic\n",
    "        sampled_seq = sampled[0].cpu().numpy()\n",
    "        \n",
    "        # Compute recovery\n",
    "        recovery = (sampled_seq == true_seq).mean()\n",
    "        recoveries.append(recovery)\n",
    "    \n",
    "    return np.mean(recoveries), np.std(recoveries)\n",
    "\n",
    "# Evaluate recovery on validation set\n",
    "print(\"Evaluating sequence recovery on validation set:\\n\")\n",
    "\n",
    "for i in range(min(5, len(val_data))):\n",
    "    mean_recovery, std_recovery = compute_recovery(model, val_data[i], num_samples=5)\n",
    "    print(f\"Protein {i+1}: {mean_recovery:.2%} Â± {std_recovery:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation metrics\n",
    "val_loss, val_acc, val_perplexity = evaluate(model, val_loader, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final Model Performance\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "print(f\"Validation Perplexity: {val_perplexity:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated:\n",
    "\n",
    "1. **Data Processing**: Converting protein structures to PyG graphs\n",
    "2. **Model Architecture**: Encoder-decoder GNN with attention\n",
    "3. **Training**: Teacher forcing with cross-entropy loss\n",
    "4. **Sampling**: Autoregressive sequence generation\n",
    "5. **Evaluation**: Perplexity and sequence recovery metrics\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Train on real protein datasets (CATH, PDB)\n",
    "- Experiment with different architectures (MPNN vs GAT)\n",
    "- Try different hyperparameters (hidden dim, num layers, etc.)\n",
    "- Evaluate on benchmark datasets (SPIN2, Ollikainen)\n",
    "- Compare with baseline models\n",
    "\n",
    "## References\n",
    "\n",
    "- Ingraham et al. \"Generative Models for Graph-Based Protein Design\" (NeurIPS 2019)\n",
    "- PyTorch Geometric Documentation: https://pytorch-geometric.readthedocs.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
