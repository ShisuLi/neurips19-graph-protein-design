{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Struct2Seq from Scratch: A Step-by-Step Guide\n",
    "\n",
    "This notebook teaches you how to build the Struct2Seq model from the ground up. We'll construct each component step by step, explaining the algorithms, mathematics, and implementation details.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand protein structure representation as graphs\n",
    "- Learn how to extract geometric features from 3D coordinates\n",
    "- Build graph attention mechanisms from scratch\n",
    "- Construct the full autoregressive sequence generation model\n",
    "- Understand how each component works together\n",
    "\n",
    "**Table of Contents:**\n",
    "1. [Introduction: Proteins as Graphs](#section1)\n",
    "2. [Part 1: Protein Featurization](#section2)\n",
    "3. [Part 2: Graph Operations](#section3)\n",
    "4. [Part 3: Attention Mechanisms](#section4)\n",
    "5. [Part 4: Transformer Layers](#section5)\n",
    "6. [Part 5: The Complete Struct2Seq Model](#section6)\n",
    "7. [Part 6: Training and Inference](#section7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section1'></a>\n",
    "## 1. Introduction: Proteins as Graphs\n",
    "\n",
    "### What is a Protein?\n",
    "\n",
    "A protein is a chain of amino acids that folds into a 3D structure. Each amino acid has a backbone consisting of 4 atoms:\n",
    "- **N** (Nitrogen)\n",
    "- **Cα** (Alpha Carbon) \n",
    "- **C** (Carbon)\n",
    "- **O** (Oxygen)\n",
    "\n",
    "### Graph Representation\n",
    "\n",
    "We represent proteins as graphs:\n",
    "- **Nodes (V)**: Each residue (amino acid) is a node\n",
    "- **Edges (E)**: Connect k-nearest neighbors in 3D space\n",
    "- **Node Features**: Geometric properties (angles, positions)\n",
    "- **Edge Features**: Pairwise relationships (distances, orientations)\n",
    "\n",
    "```\n",
    "Mathematical Notation:\n",
    "G = (V, E)  where:\n",
    "- V = {v₁, v₂, ..., vₙ}  (n residues)\n",
    "- E ⊆ V × V               (edges between neighbors)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load a protein structure\n",
    "def load_example_protein():\n",
    "    \"\"\"Load a simple protein example from the dataset\"\"\"\n",
    "    try:\n",
    "        with open('../data/chain_set.jsonl', 'r') as f:\n",
    "            # Load first protein\n",
    "            protein = json.loads(f.readline())\n",
    "        return protein\n",
    "    except:\n",
    "        print(\"Dataset not found. Creating synthetic example...\")\n",
    "        # Create a simple synthetic protein\n",
    "        n_residues = 10\n",
    "        return {\n",
    "            'name': 'example',\n",
    "            'seq': 'ACDEFGHIKL',\n",
    "            'coords': {\n",
    "                'N': np.random.randn(n_residues, 3).tolist(),\n",
    "                'CA': np.random.randn(n_residues, 3).tolist(),\n",
    "                'C': np.random.randn(n_residues, 3).tolist(),\n",
    "                'O': np.random.randn(n_residues, 3).tolist()\n",
    "            }\n",
    "        }\n",
    "\n",
    "protein = load_example_protein()\n",
    "print(f\"Protein: {protein['name']}\")\n",
    "print(f\"Sequence: {protein['seq']}\")\n",
    "print(f\"Length: {len(protein['seq'])} residues\")\n",
    "print(f\"\\nCoordinate shape: {len(protein['coords']['CA'])} x 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the protein backbone\n",
    "def visualize_backbone(coords_dict, title=\"Protein Backbone\"):\n",
    "    \"\"\"Simple 3D visualization of protein backbone\"\"\"\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Extract CA coordinates\n",
    "    ca_coords = np.array(coords_dict['CA'])\n",
    "    \n",
    "    # Plot backbone trace\n",
    "    ax.plot(ca_coords[:, 0], ca_coords[:, 1], ca_coords[:, 2], \n",
    "            'b-', linewidth=2, label='Backbone')\n",
    "    ax.scatter(ca_coords[:, 0], ca_coords[:, 1], ca_coords[:, 2], \n",
    "               c='red', s=50, label='Cα atoms')\n",
    "    \n",
    "    ax.set_xlabel('X (Å)')\n",
    "    ax.set_ylabel('Y (Å)')\n",
    "    ax.set_zlabel('Z (Å)')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_backbone(protein['coords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section2'></a>\n",
    "## 2. Part 1: Protein Featurization\n",
    "\n",
    "The first step is converting 3D coordinates into meaningful features. We'll implement:\n",
    "\n",
    "### 2.1 Distance Calculations and k-NN Graph\n",
    "### 2.2 Radial Basis Functions (RBF)\n",
    "### 2.3 Dihedral Angles (φ, ψ, ω)\n",
    "### 2.4 Orientations and Quaternions\n",
    "\n",
    "**Reference:** See `struct2seq/protein_features.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Building the k-NN Graph\n",
    "\n",
    "**Algorithm:**\n",
    "1. Compute pairwise Euclidean distances between all Cα atoms\n",
    "2. For each residue, find k nearest neighbors\n",
    "3. Store neighbor indices for graph construction\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "```\n",
    "D[i,j] = ||X[i] - X[j]||₂  (Euclidean distance)\n",
    "E_idx[i] = argsort(D[i])[:k]  (k nearest neighbors)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_distances(X, mask, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute pairwise Euclidean distances between all residues.\n",
    "    \n",
    "    Args:\n",
    "        X: Coordinates [batch_size, n_residues, 3]\n",
    "        mask: Valid residue mask [batch_size, n_residues]\n",
    "        eps: Small constant for numerical stability\n",
    "    \n",
    "    Returns:\n",
    "        D: Distance matrix [batch_size, n_residues, n_residues]\n",
    "    \"\"\"\n",
    "    # Create 2D mask: valid if both residues are valid\n",
    "    mask_2D = mask.unsqueeze(1) * mask.unsqueeze(2)  # [B, N, N]\n",
    "    \n",
    "    # Compute pairwise differences: X[i] - X[j]\n",
    "    dX = X.unsqueeze(1) - X.unsqueeze(2)  # [B, N, N, 3]\n",
    "    \n",
    "    # Compute distances: ||X[i] - X[j]||\n",
    "    D = torch.sqrt(torch.sum(dX**2, dim=-1) + eps)  # [B, N, N]\n",
    "    \n",
    "    # Mask invalid distances\n",
    "    D = mask_2D * D\n",
    "    \n",
    "    return D, mask_2D\n",
    "\n",
    "# Test the function\n",
    "# Create example coordinates\n",
    "X_example = torch.tensor(protein['coords']['CA']).unsqueeze(0).float()  # [1, N, 3]\n",
    "mask_example = torch.ones(1, len(protein['seq']))  # [1, N]\n",
    "\n",
    "D, mask_2D = compute_pairwise_distances(X_example, mask_example)\n",
    "print(f\"Distance matrix shape: {D.shape}\")\n",
    "print(f\"\\nDistance matrix (first 5x5):\")\n",
    "print(D[0, :5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knn_graph(D, mask_2D, k=30):\n",
    "    \"\"\"\n",
    "    Build k-nearest neighbors graph.\n",
    "    \n",
    "    Args:\n",
    "        D: Distance matrix [batch_size, n_residues, n_residues]\n",
    "        mask_2D: Valid pair mask [batch_size, n_residues, n_residues]\n",
    "        k: Number of nearest neighbors\n",
    "    \n",
    "    Returns:\n",
    "        D_neighbors: Distances to k neighbors [B, N, k]\n",
    "        E_idx: Indices of k neighbors [B, N, k]\n",
    "    \"\"\"\n",
    "    # Set invalid distances to large value so they won't be selected\n",
    "    D_max = torch.max(D, dim=-1, keepdim=True)[0]\n",
    "    D_adjusted = D + (1.0 - mask_2D) * D_max\n",
    "    \n",
    "    # Find k nearest neighbors (smallest distances)\n",
    "    D_neighbors, E_idx = torch.topk(D_adjusted, k, dim=-1, largest=False)\n",
    "    \n",
    "    return D_neighbors, E_idx\n",
    "\n",
    "# Test k-NN graph construction\n",
    "k = 5  # Use smaller k for visualization\n",
    "D_neighbors, E_idx = build_knn_graph(D, mask_2D, k=k)\n",
    "\n",
    "print(f\"Neighbor distances shape: {D_neighbors.shape}\")\n",
    "print(f\"Neighbor indices shape: {E_idx.shape}\")\n",
    "print(f\"\\nNeighbors of residue 0: {E_idx[0, 0]}\")\n",
    "print(f\"Distances to neighbors: {D_neighbors[0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the k-NN graph\n",
    "def visualize_knn_graph(E_idx, title=\"k-NN Graph Connectivity\"):\n",
    "    \"\"\"\n",
    "    Visualize the k-NN graph as an adjacency matrix.\n",
    "    \"\"\"\n",
    "    n_residues = E_idx.shape[1]\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    adj_matrix = torch.zeros(n_residues, n_residues)\n",
    "    for i in range(n_residues):\n",
    "        for j in E_idx[0, i]:\n",
    "            adj_matrix[i, j] = 1\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(adj_matrix.numpy(), cmap='Blues', interpolation='nearest')\n",
    "    plt.colorbar(label='Connected')\n",
    "    plt.xlabel('Residue j')\n",
    "    plt.ylabel('Residue i')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_knn_graph(E_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Radial Basis Functions (RBF)\n",
    "\n",
    "RBF encoding represents distances as smooth features:\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "```\n",
    "RBF(d) = exp(-((d - μᵢ) / σ)²)  for i = 1..num_rbf\n",
    "μᵢ = linspace(0, 20Å, num_rbf)  (Gaussian centers)\n",
    "σ = 20 / num_rbf                (Gaussian width)\n",
    "```\n",
    "\n",
    "This creates a smooth, differentiable encoding of distance information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_encoding(D, num_rbf=16, d_min=0.0, d_max=20.0):\n",
    "    \"\"\"\n",
    "    Encode distances using Radial Basis Functions.\n",
    "    \n",
    "    Args:\n",
    "        D: Distances [batch_size, n_residues, k_neighbors]\n",
    "        num_rbf: Number of RBF kernels\n",
    "        d_min: Minimum distance for RBF centers\n",
    "        d_max: Maximum distance for RBF centers\n",
    "    \n",
    "    Returns:\n",
    "        RBF features [batch_size, n_residues, k_neighbors, num_rbf]\n",
    "    \"\"\"\n",
    "    # Create RBF centers (μ)\n",
    "    rbf_centers = torch.linspace(d_min, d_max, num_rbf)  # [num_rbf]\n",
    "    rbf_centers = rbf_centers.view(1, 1, 1, -1)  # [1, 1, 1, num_rbf]\n",
    "    \n",
    "    # RBF width (σ)\n",
    "    rbf_width = (d_max - d_min) / num_rbf\n",
    "    \n",
    "    # Expand distances for broadcasting\n",
    "    D_expanded = D.unsqueeze(-1)  # [B, N, K, 1]\n",
    "    \n",
    "    # Compute RBF: exp(-((d - μ) / σ)²)\n",
    "    RBF = torch.exp(-((D_expanded - rbf_centers) / rbf_width) ** 2)\n",
    "    \n",
    "    return RBF\n",
    "\n",
    "# Test RBF encoding\n",
    "RBF_features = rbf_encoding(D_neighbors, num_rbf=16)\n",
    "print(f\"RBF features shape: {RBF_features.shape}\")\n",
    "print(f\"RBF features for first neighbor of residue 0:\")\n",
    "print(RBF_features[0, 0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RBF encoding\n",
    "def visualize_rbf():\n",
    "    \"\"\"Visualize how RBF encoding works\"\"\"\n",
    "    distances = torch.linspace(0, 20, 100)\n",
    "    rbf_features = rbf_encoding(distances.unsqueeze(0).unsqueeze(0), num_rbf=8)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for i in range(8):\n",
    "        plt.plot(distances.numpy(), rbf_features[0, 0, :, i].numpy(), \n",
    "                label=f'RBF {i+1}')\n",
    "    \n",
    "    plt.xlabel('Distance (Å)')\n",
    "    plt.ylabel('RBF Activation')\n",
    "    plt.title('Radial Basis Function Encoding')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_rbf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dihedral Angles\n",
    "\n",
    "Dihedral angles (φ, ψ, ω) describe the backbone geometry:\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "```\n",
    "Given 4 consecutive atoms A-B-C-D:\n",
    "1. Compute unit vectors: u₁ = (B-A)/||B-A||, u₂ = (C-B)/||C-B||, u₃ = (D-C)/||D-C||\n",
    "2. Compute normals: n₁ = u₁ × u₂, n₂ = u₂ × u₃\n",
    "3. Dihedral angle: θ = sign(u₁·n₂) × arccos(n₁·n₂)\n",
    "4. Encode as: [cos(θ), sin(θ)] (circular representation)\n",
    "```\n",
    "\n",
    "**In proteins:**\n",
    "- φ (phi): N-Cα-C-N dihedral\n",
    "- ψ (psi): Cα-C-N-Cα dihedral  \n",
    "- ω (omega): C-N-Cα-C dihedral\n",
    "\n",
    "**Reference:** `protein_features.py:294-337`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dihedrals(X, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Compute backbone dihedral angles (φ, ψ, ω).\n",
    "    \n",
    "    Args:\n",
    "        X: Backbone coordinates [batch_size, n_residues, 4, 3]\n",
    "           where 4 atoms are [N, CA, C, O]\n",
    "    \n",
    "    Returns:\n",
    "        Dihedral features [batch_size, n_residues, 6]\n",
    "        (cos φ, sin φ, cos ψ, sin ψ, cos ω, sin ω)\n",
    "    \"\"\"\n",
    "    # Take only N, CA, C (first 3 atoms)\n",
    "    X = X[:, :, :3, :].reshape(X.shape[0], 3 * X.shape[1], 3)\n",
    "    \n",
    "    # Compute unit vectors between consecutive atoms\n",
    "    dX = X[:, 1:, :] - X[:, :-1, :]  # [B, 3N-1, 3]\n",
    "    U = F.normalize(dX, dim=-1)  # Unit vectors\n",
    "    \n",
    "    # Get consecutive triplets of unit vectors\n",
    "    u_0 = U[:, 2:, :]   # Third vector\n",
    "    u_1 = U[:, 1:-1, :] # Middle vector\n",
    "    u_2 = U[:, :-2, :]  # First vector\n",
    "    \n",
    "    # Compute normal vectors (perpendicular to planes)\n",
    "    n_1 = F.normalize(torch.cross(u_1, u_0, dim=-1), dim=-1)\n",
    "    n_2 = F.normalize(torch.cross(u_2, u_1, dim=-1), dim=-1)\n",
    "    \n",
    "    # Compute dihedral angle\n",
    "    # cos(θ) = n₁ · n₂\n",
    "    cos_D = (n_2 * n_1).sum(-1)\n",
    "    cos_D = torch.clamp(cos_D, -1 + eps, 1 - eps)\n",
    "    \n",
    "    # θ = sign(u₂ · n₁) × arccos(cos(θ))\n",
    "    D = torch.sign((u_2 * n_1).sum(-1)) * torch.acos(cos_D)\n",
    "    \n",
    "    # Pad to account for boundary conditions\n",
    "    D = F.pad(D, (1, 2), 'constant', 0)\n",
    "    \n",
    "    # Reshape into [phi, psi, omega] per residue\n",
    "    D = D.view(D.size(0), D.size(1) // 3, 3)\n",
    "    \n",
    "    # Encode as circular features: [cos(θ), sin(θ)]\n",
    "    D_features = torch.cat([torch.cos(D), torch.sin(D)], dim=-1)\n",
    "    \n",
    "    return D_features\n",
    "\n",
    "# Test dihedral computation\n",
    "# Create backbone coordinate tensor\n",
    "X_backbone = torch.zeros(1, len(protein['seq']), 4, 3)\n",
    "for i, atom in enumerate(['N', 'CA', 'C', 'O']):\n",
    "    X_backbone[0, :, i, :] = torch.tensor(protein['coords'][atom])\n",
    "\n",
    "dihedral_features = compute_dihedrals(X_backbone)\n",
    "print(f\"Dihedral features shape: {dihedral_features.shape}\")\n",
    "print(f\"Features per residue: 6 (cos φ, sin φ, cos ψ, sin ψ, cos ω, sin ω)\")\n",
    "print(f\"\\nFirst residue dihedrals:\")\n",
    "print(dihedral_features[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Ramachandran plot (if we have enough data)\n",
    "def plot_ramachandran(dihedral_features):\n",
    "    \"\"\"Plot phi-psi angles (Ramachandran plot)\"\"\"\n",
    "    # Extract phi and psi angles\n",
    "    phi = torch.atan2(dihedral_features[:, :, 1], dihedral_features[:, :, 0])  # arctan(sin/cos)\n",
    "    psi = torch.atan2(dihedral_features[:, :, 3], dihedral_features[:, :, 2])\n",
    "    \n",
    "    phi_deg = phi.numpy().flatten() * 180 / np.pi\n",
    "    psi_deg = psi.numpy().flatten() * 180 / np.pi\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(phi_deg, psi_deg, alpha=0.6, s=30)\n",
    "    plt.xlabel('φ (phi) [degrees]')\n",
    "    plt.ylabel('ψ (psi) [degrees]')\n",
    "    plt.title('Ramachandran Plot')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim(-180, 180)\n",
    "    plt.ylim(-180, 180)\n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_ramachandran(dihedral_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Positional Encodings\n",
    "\n",
    "Positional encodings help the model understand sequence order:\n",
    "\n",
    "**Mathematical Formulation (from Transformer):**\n",
    "```\n",
    "PE(pos, 2i)   = sin(pos / 10000^(2i/d))\n",
    "PE(pos, 2i+1) = cos(pos / 10000^(2i/d))\n",
    "```\n",
    "\n",
    "For edges, we use the relative position: `pos = j - i` (neighbor index - current index)\n",
    "\n",
    "**Reference:** `protein_features.py:14-42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encodings(E_idx, num_embeddings=16):\n",
    "    \"\"\"\n",
    "    Compute positional encodings for edges based on sequence distance.\n",
    "    \n",
    "    Args:\n",
    "        E_idx: Neighbor indices [batch_size, n_residues, k_neighbors]\n",
    "        num_embeddings: Dimensionality of encoding\n",
    "    \n",
    "    Returns:\n",
    "        Positional encodings [B, N, K, num_embeddings]\n",
    "    \"\"\"\n",
    "    batch_size = E_idx.size(0)\n",
    "    n_nodes = E_idx.size(1)\n",
    "    n_neighbors = E_idx.size(2)\n",
    "    \n",
    "    # Current position indices\n",
    "    ii = torch.arange(n_nodes, dtype=torch.float32).view(1, -1, 1)\n",
    "    \n",
    "    # Relative position: j - i\n",
    "    d = (E_idx.float() - ii).unsqueeze(-1)  # [B, N, K, 1]\n",
    "    \n",
    "    # Compute frequencies (from original Transformer)\n",
    "    frequency = torch.exp(\n",
    "        torch.arange(0, num_embeddings, 2, dtype=torch.float32)\n",
    "        * -(np.log(10000.0) / num_embeddings)\n",
    "    )\n",
    "    \n",
    "    # Compute angles\n",
    "    angles = d * frequency.view(1, 1, 1, -1)  # [B, N, K, num_embeddings/2]\n",
    "    \n",
    "    # Concatenate sin and cos\n",
    "    E_pos = torch.cat([torch.cos(angles), torch.sin(angles)], dim=-1)\n",
    "    \n",
    "    return E_pos\n",
    "\n",
    "# Test positional encodings\n",
    "pos_encodings = positional_encodings(E_idx, num_embeddings=16)\n",
    "print(f\"Positional encodings shape: {pos_encodings.shape}\")\n",
    "print(f\"\\nPositional encoding for first neighbor of residue 5:\")\n",
    "print(pos_encodings[0, 5, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize positional encodings\n",
    "def visualize_positional_encodings():\n",
    "    \"\"\"Visualize positional encoding patterns\"\"\"\n",
    "    # Create sequence of relative positions\n",
    "    positions = torch.arange(-20, 21).view(1, 41, 1)\n",
    "    encodings = positional_encodings(positions, num_embeddings=16)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(encodings[0, :, 0, :].T.numpy(), aspect='auto', cmap='RdBu', \n",
    "               interpolation='nearest')\n",
    "    plt.colorbar(label='Encoding value')\n",
    "    plt.xlabel('Relative Position (j - i)')\n",
    "    plt.ylabel('Encoding Dimension')\n",
    "    plt.title('Positional Encoding Pattern')\n",
    "    plt.xticks(range(0, 41, 5), range(-20, 21, 5))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_positional_encodings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section3'></a>\n",
    "## 3. Part 2: Graph Operations\n",
    "\n",
    "Graph neural networks require specialized operations to gather information from neighbors.\n",
    "\n",
    "**Key Operations:**\n",
    "1. `gather_nodes`: Gather node features at specified indices\n",
    "2. `gather_edges`: Gather edge features at specified indices\n",
    "3. `cat_neighbors_nodes`: Concatenate neighbor and node features\n",
    "\n",
    "**Reference:** `self_attention.py:11-36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_nodes(nodes, neighbor_idx):\n",
    "    \"\"\"\n",
    "    Gather node features at neighbor indices.\n",
    "    \n",
    "    Given node features and neighbor indices, extract features\n",
    "    of neighboring nodes for each node.\n",
    "    \n",
    "    Args:\n",
    "        nodes: Node features [batch_size, n_nodes, feature_dim]\n",
    "        neighbor_idx: Neighbor indices [batch_size, n_nodes, k_neighbors]\n",
    "    \n",
    "    Returns:\n",
    "        Neighbor features [batch_size, n_nodes, k_neighbors, feature_dim]\n",
    "    \n",
    "    Example:\n",
    "        nodes = [[h₀, h₁, h₂, h₃], ...]  # Node features\n",
    "        neighbor_idx = [[1, 2], [0, 3], [1, 3], [0, 2]]  # Who are my neighbors?\n",
    "        output[0] = [h₁, h₂]  # Features of node 0's neighbors\n",
    "    \"\"\"\n",
    "    # Flatten neighbor indices for gathering\n",
    "    neighbors_flat = neighbor_idx.view(neighbor_idx.shape[0], -1)  # [B, N*K]\n",
    "    neighbors_flat = neighbors_flat.unsqueeze(-1).expand(-1, -1, nodes.size(2))  # [B, N*K, C]\n",
    "    \n",
    "    # Gather features\n",
    "    neighbor_features = torch.gather(nodes, 1, neighbors_flat)  # [B, N*K, C]\n",
    "    \n",
    "    # Reshape to [B, N, K, C]\n",
    "    neighbor_features = neighbor_features.view(\n",
    "        list(neighbor_idx.shape)[:3] + [-1]\n",
    "    )\n",
    "    \n",
    "    return neighbor_features\n",
    "\n",
    "# Test gather_nodes\n",
    "# Create dummy node features\n",
    "n_nodes = 5\n",
    "feature_dim = 4\n",
    "dummy_nodes = torch.arange(n_nodes * feature_dim).view(1, n_nodes, feature_dim).float()\n",
    "print(\"Node features:\")\n",
    "print(dummy_nodes[0])\n",
    "\n",
    "# Create neighbor indices\n",
    "dummy_neighbors = torch.tensor([[[1, 2], [0, 3], [1, 4], [0, 2], [1, 3]]])\n",
    "print(\"\\nNeighbor indices:\")\n",
    "print(dummy_neighbors[0])\n",
    "\n",
    "# Gather neighbor features\n",
    "neighbor_features = gather_nodes(dummy_nodes, dummy_neighbors)\n",
    "print(\"\\nGathered neighbor features for node 0:\")\n",
    "print(neighbor_features[0, 0])  # Should be features of nodes 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_neighbors_nodes(h_nodes, h_edges, E_idx):\n",
    "    \"\"\"\n",
    "    Concatenate node features with edge features.\n",
    "    \n",
    "    For each edge (i,j), concatenate:\n",
    "    - Edge features h_edges[i,j]\n",
    "    - Destination node features h_nodes[j]\n",
    "    \n",
    "    Args:\n",
    "        h_nodes: Node features [B, N, C_node]\n",
    "        h_edges: Edge features [B, N, K, C_edge]\n",
    "        E_idx: Edge indices [B, N, K]\n",
    "    \n",
    "    Returns:\n",
    "        Combined features [B, N, K, C_edge + C_node]\n",
    "    \"\"\"\n",
    "    # Gather node features at neighbor positions\n",
    "    h_nodes_neighbors = gather_nodes(h_nodes, E_idx)\n",
    "    \n",
    "    # Concatenate edge and node features\n",
    "    h_combined = torch.cat([h_edges, h_nodes_neighbors], dim=-1)\n",
    "    \n",
    "    return h_combined\n",
    "\n",
    "# Test cat_neighbors_nodes\n",
    "dummy_edges = torch.randn(1, n_nodes, 2, 3)  # Edge features\n",
    "combined = cat_neighbors_nodes(dummy_nodes, dummy_edges, dummy_neighbors)\n",
    "print(f\"Combined features shape: {combined.shape}\")\n",
    "print(f\"Expected: [1, {n_nodes}, 2, {3 + feature_dim}] (edge_dim + node_dim)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section4'></a>\n",
    "## 4. Part 3: Attention Mechanisms\n",
    "\n",
    "Attention allows the model to focus on relevant parts of the graph.\n",
    "\n",
    "### Multi-Head Attention\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "```\n",
    "Q = W_Q × h_V         (Query from current node)\n",
    "K = W_K × h_E         (Keys from edges/neighbors)\n",
    "V = W_V × h_E         (Values from edges/neighbors)\n",
    "\n",
    "Attention(Q,K,V) = softmax(QK^T / √d) × V\n",
    "\n",
    "Multi-Head: Run multiple attention heads in parallel\n",
    "```\n",
    "\n",
    "**Reference:** `self_attention.py:155-210`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeighborAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head attention over graph neighbors.\n",
    "    \n",
    "    This is the core mechanism that allows nodes to aggregate\n",
    "    information from their neighbors adaptively.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden, num_in, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        # Linear transformations for Q, K, V\n",
    "        self.W_Q = nn.Linear(num_hidden, num_hidden, bias=False)  # Query\n",
    "        self.W_K = nn.Linear(num_in, num_hidden, bias=False)      # Key\n",
    "        self.W_V = nn.Linear(num_in, num_hidden, bias=False)      # Value\n",
    "        self.W_O = nn.Linear(num_hidden, num_hidden, bias=False)  # Output\n",
    "    \n",
    "    def forward(self, h_V, h_E, mask_attend=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h_V: Node features [B, N, num_hidden]\n",
    "            h_E: Edge features [B, N, K, num_in]\n",
    "            mask_attend: Attention mask [B, N, K] (optional)\n",
    "        \n",
    "        Returns:\n",
    "            Updated node features [B, N, num_hidden]\n",
    "        \"\"\"\n",
    "        batch_size, n_nodes, n_neighbors = h_E.shape[:3]\n",
    "        n_heads = self.num_heads\n",
    "        d = self.num_hidden // n_heads  # Dimension per head\n",
    "        \n",
    "        # === Step 1: Compute Q, K, V ===\n",
    "        # Query: from current node (broadcast to all neighbors)\n",
    "        Q = self.W_Q(h_V)  # [B, N, num_hidden]\n",
    "        Q = Q.view(batch_size, n_nodes, 1, n_heads, 1, d)\n",
    "        \n",
    "        # Keys: from edge features\n",
    "        K = self.W_K(h_E)  # [B, N, K, num_hidden]\n",
    "        K = K.view(batch_size, n_nodes, n_neighbors, n_heads, d, 1)\n",
    "        \n",
    "        # Values: from edge features\n",
    "        V = self.W_V(h_E)  # [B, N, K, num_hidden]\n",
    "        V = V.view(batch_size, n_nodes, n_neighbors, n_heads, d)\n",
    "        \n",
    "        # === Step 2: Compute attention scores ===\n",
    "        # Attention logits: QK^T\n",
    "        attend_logits = torch.matmul(Q, K)  # [B, N, K, n_heads, 1, 1]\n",
    "        attend_logits = attend_logits.view(batch_size, n_nodes, n_neighbors, n_heads)\n",
    "        attend_logits = attend_logits.transpose(-2, -1)  # [B, N, n_heads, K]\n",
    "        \n",
    "        # Scale by √d (for numerical stability)\n",
    "        attend_logits = attend_logits / np.sqrt(d)\n",
    "        \n",
    "        # === Step 3: Apply attention mask (if provided) ===\n",
    "        if mask_attend is not None:\n",
    "            # Expand mask for multiple heads\n",
    "            mask = mask_attend.unsqueeze(2).expand(-1, -1, n_heads, -1)\n",
    "            # Set masked positions to -inf before softmax\n",
    "            attend_logits = torch.where(\n",
    "                mask > 0, \n",
    "                attend_logits, \n",
    "                torch.tensor(float('-inf'))\n",
    "            )\n",
    "        \n",
    "        # === Step 4: Softmax to get attention weights ===\n",
    "        attend = F.softmax(attend_logits, dim=-1)  # [B, N, n_heads, K]\n",
    "        \n",
    "        # === Step 5: Weighted sum of values ===\n",
    "        # attend: [B, N, n_heads, K] → [B, N, n_heads, 1, K]\n",
    "        # V: [B, N, K, n_heads, d] → [B, N, n_heads, K, d]\n",
    "        h_V_update = torch.matmul(\n",
    "            attend.unsqueeze(-2),  # [B, N, n_heads, 1, K]\n",
    "            V.transpose(2, 3)       # [B, N, n_heads, K, d]\n",
    "        )  # [B, N, n_heads, 1, d]\n",
    "        \n",
    "        # Reshape back to [B, N, num_hidden]\n",
    "        h_V_update = h_V_update.view(batch_size, n_nodes, self.num_hidden)\n",
    "        \n",
    "        # === Step 6: Output projection ===\n",
    "        h_V_update = self.W_O(h_V_update)\n",
    "        \n",
    "        return h_V_update\n",
    "\n",
    "# Test the attention mechanism\n",
    "attention = NeighborAttention(num_hidden=32, num_in=48, num_heads=4)\n",
    "\n",
    "# Create dummy inputs\n",
    "h_V_test = torch.randn(1, 10, 32)   # 10 nodes, 32 features\n",
    "h_E_test = torch.randn(1, 10, 5, 48)  # Each node has 5 neighbors, 48 edge features\n",
    "\n",
    "# Apply attention\n",
    "h_V_updated = attention(h_V_test, h_E_test)\n",
    "print(f\"Input node features shape: {h_V_test.shape}\")\n",
    "print(f\"Edge features shape: {h_E_test.shape}\")\n",
    "print(f\"Output node features shape: {h_V_updated.shape}\")\n",
    "print(f\"\\nAttention successfully updated node features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Multi-Head Attention\n",
    "\n",
    "**Why multiple heads?**\n",
    "- Different heads can attend to different aspects of the structure\n",
    "- Head 1 might focus on nearby residues\n",
    "- Head 2 might focus on specific structural motifs\n",
    "- Head 3 might focus on long-range contacts\n",
    "\n",
    "**Visualization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_pattern(attention_weights, head_idx=0):\n",
    "    \"\"\"\n",
    "    Visualize attention pattern for a specific head.\n",
    "    \n",
    "    Args:\n",
    "        attention_weights: [B, N, num_heads, K]\n",
    "        head_idx: Which attention head to visualize\n",
    "    \"\"\"\n",
    "    # Extract attention for specific head\n",
    "    attn = attention_weights[0, :, head_idx, :].detach().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(attn, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "    plt.colorbar(label='Attention Weight')\n",
    "    plt.xlabel('Neighbor Index')\n",
    "    plt.ylabel('Residue')\n",
    "    plt.title(f'Attention Pattern (Head {head_idx})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Note: Actual attention weights are computed inside the forward pass.\")\n",
    "print(\"In practice, you would extract them during model execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section5'></a>\n",
    "## 5. Part 4: Transformer Layers\n",
    "\n",
    "A complete Transformer layer combines attention with feed-forward networks and normalization.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input → Attention → Add & Norm → Feed-Forward → Add & Norm → Output\n",
    "        ↓                           ↓\n",
    "     Residual                   Residual\n",
    "```\n",
    "\n",
    "**Reference:** `self_attention.py:60-101`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(nn.Module):\n",
    "    \"\"\"Layer normalization.\"\"\"\n",
    "    def __init__(self, features, epsilon=1e-6):\n",
    "        super().__init__()\n",
    "        self.gain = nn.Parameter(torch.ones(features))\n",
    "        self.bias = nn.Parameter(torch.zeros(features))\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def forward(self, x, dim=-1):\n",
    "        # Compute mean and std\n",
    "        mu = x.mean(dim, keepdim=True)\n",
    "        sigma = torch.sqrt(x.var(dim, keepdim=True) + self.epsilon)\n",
    "        \n",
    "        # Normalize\n",
    "        return self.gain * (x - mu) / sigma + self.bias\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    \"\"\"Feed-forward network applied to each position.\"\"\"\n",
    "    def __init__(self, num_hidden, num_ff):\n",
    "        super().__init__()\n",
    "        self.W_in = nn.Linear(num_hidden, num_ff)\n",
    "        self.W_out = nn.Linear(num_ff, num_hidden)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        return self.W_out(F.relu(self.W_in(h)))\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Transformer layer with attention and feed-forward.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Multi-head attention\n",
    "    2. Residual connection + Layer norm\n",
    "    3. Position-wise feed-forward\n",
    "    4. Residual connection + Layer norm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden, num_in, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_hidden = num_hidden\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Two normalization layers\n",
    "        self.norm = nn.ModuleList([Normalize(num_hidden) for _ in range(2)])\n",
    "        \n",
    "        # Attention and feed-forward\n",
    "        self.attention = NeighborAttention(num_hidden, num_in, num_heads)\n",
    "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
    "    \n",
    "    def forward(self, h_V, h_E, mask_V=None, mask_attend=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h_V: Node features [B, N, num_hidden]\n",
    "            h_E: Edge features [B, N, K, num_in]\n",
    "            mask_V: Node mask [B, N] (optional)\n",
    "            mask_attend: Attention mask [B, N, K] (optional)\n",
    "        \n",
    "        Returns:\n",
    "            Updated node features [B, N, num_hidden]\n",
    "        \"\"\"\n",
    "        # === Step 1: Self-attention ===\n",
    "        dh = self.attention(h_V, h_E, mask_attend)\n",
    "        \n",
    "        # Residual connection + normalization\n",
    "        h_V = self.norm[0](h_V + self.dropout(dh))\n",
    "        \n",
    "        # === Step 2: Feed-forward ===\n",
    "        dh = self.dense(h_V)\n",
    "        \n",
    "        # Residual connection + normalization\n",
    "        h_V = self.norm[1](h_V + self.dropout(dh))\n",
    "        \n",
    "        # === Step 3: Apply node mask ===\n",
    "        if mask_V is not None:\n",
    "            mask_V = mask_V.unsqueeze(-1)\n",
    "            h_V = mask_V * h_V\n",
    "        \n",
    "        return h_V\n",
    "\n",
    "# Test the transformer layer\n",
    "transformer = TransformerLayer(num_hidden=32, num_in=48, num_heads=4, dropout=0.1)\n",
    "\n",
    "h_V_test = torch.randn(2, 10, 32)     # 2 proteins, 10 residues each\n",
    "h_E_test = torch.randn(2, 10, 5, 48)  # 5 neighbors per residue\n",
    "\n",
    "h_V_out = transformer(h_V_test, h_E_test)\n",
    "print(f\"Input shape: {h_V_test.shape}\")\n",
    "print(f\"Output shape: {h_V_out.shape}\")\n",
    "print(f\"\\nTransformer layer executed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Residual Connections?\n",
    "\n",
    "Residual connections (skip connections) are crucial:\n",
    "\n",
    "**Without residual:** `h_new = Transform(h_old)`\n",
    "**With residual:** `h_new = h_old + Transform(h_old)`\n",
    "\n",
    "**Benefits:**\n",
    "1. Easier gradient flow (helps training deep networks)\n",
    "2. Allows the model to learn incremental refinements\n",
    "3. Prevents vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section6'></a>\n",
    "## 6. Part 5: The Complete Struct2Seq Model\n",
    "\n",
    "Now we assemble everything into the complete model!\n",
    "\n",
    "**Architecture Overview:**\n",
    "```\n",
    "Input: 3D Structure (X) and Sequence (S)\n",
    "    ↓\n",
    "1. Featurization → Node features (V), Edge features (E)\n",
    "    ↓\n",
    "2. Encoder (3 layers) → Encode structure\n",
    "    ↓\n",
    "3. Decoder (3 layers) → Generate sequence autoregressively\n",
    "    ↓\n",
    "Output: Log probabilities over amino acids\n",
    "```\n",
    "\n",
    "**Reference:** `struct2seq/struct2seq.py:14-219`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleProteinFeatures(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified protein featurization for demonstration.\n",
    "    \n",
    "    In the real implementation, this is much more sophisticated\n",
    "    (see protein_features.py).\n",
    "    \"\"\"\n",
    "    def __init__(self, node_features, edge_features, top_k=30):\n",
    "        super().__init__()\n",
    "        self.top_k = top_k\n",
    "        self.node_embedding = nn.Linear(6, node_features)  # 6D dihedral features\n",
    "        self.edge_embedding = nn.Linear(32, edge_features)  # RBF + positional\n",
    "    \n",
    "    def forward(self, X, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: Coordinates [B, N, 4, 3] (N, CA, C, O)\n",
    "            mask: Valid residues [B, N]\n",
    "        \n",
    "        Returns:\n",
    "            V: Node features [B, N, node_features]\n",
    "            E: Edge features [B, N, K, edge_features]\n",
    "            E_idx: Edge indices [B, N, K]\n",
    "        \"\"\"\n",
    "        # Extract CA coordinates\n",
    "        X_ca = X[:, :, 1, :]  # [B, N, 3]\n",
    "        \n",
    "        # Compute distances and build k-NN graph\n",
    "        D, mask_2D = compute_pairwise_distances(X_ca, mask)\n",
    "        D_neighbors, E_idx = build_knn_graph(D, mask_2D, k=self.top_k)\n",
    "        \n",
    "        # Node features: dihedral angles\n",
    "        V = compute_dihedrals(X)\n",
    "        V = self.node_embedding(V)\n",
    "        \n",
    "        # Edge features: RBF + positional encodings\n",
    "        rbf = rbf_encoding(D_neighbors, num_rbf=16)\n",
    "        pos = positional_encodings(E_idx, num_embeddings=16)\n",
    "        E = torch.cat([rbf, pos], dim=-1)\n",
    "        E = self.edge_embedding(E)\n",
    "        \n",
    "        return V, E, E_idx\n",
    "\n",
    "# Test featurization\n",
    "featurizer = SimpleProteinFeatures(node_features=32, edge_features=48, top_k=10)\n",
    "V, E, E_idx = featurizer(X_backbone, mask_example)\n",
    "print(f\"Node features: {V.shape}\")\n",
    "print(f\"Edge features: {E.shape}\")\n",
    "print(f\"Edge indices: {E_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Struct2Seq model for protein design.\n",
    "    \n",
    "    The model consists of:\n",
    "    1. Featurization: Convert 3D structure to graph\n",
    "    2. Encoder: Process structure information\n",
    "    3. Decoder: Generate sequence autoregressively\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_letters=20,      # Amino acid vocabulary size\n",
    "                 node_features=128,   # Node feature dimension\n",
    "                 edge_features=128,   # Edge feature dimension\n",
    "                 hidden_dim=128,      # Hidden dimension\n",
    "                 num_encoder_layers=3,\n",
    "                 num_decoder_layers=3,\n",
    "                 num_heads=4,\n",
    "                 k_neighbors=30,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # === 1. Featurization ===\n",
    "        self.features = SimpleProteinFeatures(\n",
    "            node_features, edge_features, top_k=k_neighbors\n",
    "        )\n",
    "        \n",
    "        # === 2. Embeddings ===\n",
    "        # Node and edge embeddings\n",
    "        self.W_v = nn.Linear(node_features, hidden_dim)\n",
    "        self.W_e = nn.Linear(edge_features, hidden_dim)\n",
    "        # Sequence embedding\n",
    "        self.W_s = nn.Embedding(num_letters, hidden_dim)\n",
    "        \n",
    "        # === 3. Encoder layers ===\n",
    "        # Process structural information (unmasked)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerLayer(hidden_dim, hidden_dim * 2, num_heads, dropout)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        # === 4. Decoder layers ===\n",
    "        # Generate sequence autoregressively (masked)\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            TransformerLayer(hidden_dim, hidden_dim * 3, num_heads, dropout)\n",
    "            for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "        \n",
    "        # === 5. Output projection ===\n",
    "        self.W_out = nn.Linear(hidden_dim, num_letters)\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self._init_params()\n",
    "    \n",
    "    def _init_params(self):\n",
    "        \"\"\"Xavier initialization for better training.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def _autoregressive_mask(self, E_idx):\n",
    "        \"\"\"\n",
    "        Create mask for autoregressive decoding.\n",
    "        \n",
    "        Position i can only attend to positions < i.\n",
    "        \n",
    "        Args:\n",
    "            E_idx: Neighbor indices [B, N, K]\n",
    "        \n",
    "        Returns:\n",
    "            Mask [B, N, K] where mask[i,j] = 1 if j < i\n",
    "        \"\"\"\n",
    "        n_nodes = E_idx.size(1)\n",
    "        ii = torch.arange(n_nodes).view(1, -1, 1)\n",
    "        \n",
    "        # mask = 1 if neighbor_idx < current_idx\n",
    "        mask = (E_idx - ii < 0).float()\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def forward(self, X, S, mask):\n",
    "        \"\"\"\n",
    "        Forward pass of Struct2Seq.\n",
    "        \n",
    "        Args:\n",
    "            X: Coordinates [B, N, 4, 3]\n",
    "            S: Sequence [B, N] (amino acid indices)\n",
    "            mask: Valid residues [B, N]\n",
    "        \n",
    "        Returns:\n",
    "            Log probabilities [B, N, 20]\n",
    "        \"\"\"\n",
    "        # === Step 1: Featurization ===\n",
    "        V, E, E_idx = self.features(X, mask)\n",
    "        h_V = self.W_v(V)\n",
    "        h_E = self.W_e(E)\n",
    "        \n",
    "        # === Step 2: Encoder (unmasked attention) ===\n",
    "        # Build attention mask (attend to all valid neighbors)\n",
    "        mask_attend = gather_nodes(mask.unsqueeze(-1), E_idx).squeeze(-1)\n",
    "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            # Combine edge features with node features\n",
    "            h_EV = cat_neighbors_nodes(h_V, h_E, E_idx)\n",
    "            h_V = layer(h_V, h_EV, mask_V=mask, mask_attend=mask_attend)\n",
    "        \n",
    "        # === Step 3: Prepare decoder ===\n",
    "        # Embed the sequence\n",
    "        h_S = self.W_s(S)\n",
    "        h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
    "        \n",
    "        # Encoder features (for positions we haven't generated yet)\n",
    "        h_ES_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
    "        h_ESV_encoder = cat_neighbors_nodes(h_V, h_ES_encoder, E_idx)\n",
    "        \n",
    "        # === Step 4: Decoder (autoregressive) ===\n",
    "        # Create autoregressive mask\n",
    "        mask_ar = self._autoregressive_mask(E_idx).unsqueeze(-1)\n",
    "        mask_1D = mask.view(mask.size(0), mask.size(1), 1, 1)\n",
    "        mask_bw = mask_1D * mask_ar  # Backward (already generated)\n",
    "        mask_fw = mask_1D * (1 - mask_ar)  # Forward (encoder info)\n",
    "        \n",
    "        h_ESV_encoder_fw = mask_fw * h_ESV_encoder\n",
    "        \n",
    "        for layer in self.decoder_layers:\n",
    "            # Combine structure + sequence information\n",
    "            h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
    "            # Mask: attend backward to generated sequence,\n",
    "            # forward to structure\n",
    "            h_ESV = mask_bw * h_ESV + h_ESV_encoder_fw\n",
    "            h_V = layer(h_V, h_ESV, mask_V=mask)\n",
    "        \n",
    "        # === Step 5: Output projection ===\n",
    "        logits = self.W_out(h_V)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        return log_probs\n",
    "\n",
    "# Create the model\n",
    "model = Struct2Seq(\n",
    "    num_letters=20,\n",
    "    node_features=32,\n",
    "    edge_features=48,\n",
    "    hidden_dim=32,\n",
    "    num_encoder_layers=2,\n",
    "    num_decoder_layers=2,\n",
    "    num_heads=4,\n",
    "    k_neighbors=10,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(\"Struct2Seq model created!\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the complete model\n",
    "# Create dummy input\n",
    "batch_size = 2\n",
    "n_residues = 20\n",
    "\n",
    "X_test = torch.randn(batch_size, n_residues, 4, 3)  # Coordinates\n",
    "S_test = torch.randint(0, 20, (batch_size, n_residues))  # Sequence\n",
    "mask_test = torch.ones(batch_size, n_residues)  # All valid\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    log_probs = model(X_test, S_test, mask_test)\n",
    "\n",
    "print(f\"Input shape: {X_test.shape}\")\n",
    "print(f\"Output log probabilities shape: {log_probs.shape}\")\n",
    "print(f\"Expected: [batch_size={batch_size}, n_residues={n_residues}, vocab_size=20]\")\n",
    "print(f\"\\nModel forward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Autoregressive Mask\n",
    "\n",
    "The decoder uses **autoregressive masking** to generate sequences:\n",
    "\n",
    "```\n",
    "Position:  0  1  2  3  4\n",
    "           ↓  ↓  ↓  ↓  ↓\n",
    "Gen 0:    [?  ?  ?  ?  ?]  → Predict position 0\n",
    "Gen 1:    [A  ?  ?  ?  ?]  → Predict position 1 (seeing A)\n",
    "Gen 2:    [A  C  ?  ?  ?]  → Predict position 2 (seeing A, C)\n",
    "Gen 3:    [A  C  D  ?  ?]  → Predict position 3 (seeing A, C, D)\n",
    "...\n",
    "```\n",
    "\n",
    "**Key insight:** Position i can only see positions < i. This prevents \"cheating\" during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize autoregressive mask\n",
    "def visualize_ar_mask():\n",
    "    \"\"\"Show the autoregressive masking pattern.\"\"\"\n",
    "    n = 15\n",
    "    E_idx = torch.arange(n).unsqueeze(0).unsqueeze(0).expand(1, n, n)\n",
    "    mask = model._autoregressive_mask(E_idx)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(mask[0].numpy(), cmap='Blues', interpolation='nearest')\n",
    "    plt.colorbar(label='Can Attend')\n",
    "    plt.xlabel('Neighbor Position')\n",
    "    plt.ylabel('Current Position')\n",
    "    plt.title('Autoregressive Attention Mask\\n(1 = can attend, 0 = masked)')\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(min(5, n)):\n",
    "        for j in range(min(5, n)):\n",
    "            text = plt.text(j, i, int(mask[0, i, j].item()),\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_ar_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='section7'></a>\n",
    "## 7. Part 6: Training and Inference\n",
    "\n",
    "### Training the Model\n",
    "\n",
    "**Loss Function:** Negative log-likelihood\n",
    "```\n",
    "L = -Σᵢ log P(sᵢ | structure, s₁, ..., sᵢ₋₁)\n",
    "```\n",
    "\n",
    "Where sᵢ is the true amino acid at position i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(log_probs, S_true, mask):\n",
    "    \"\"\"\n",
    "    Compute negative log-likelihood loss.\n",
    "    \n",
    "    Args:\n",
    "        log_probs: Model predictions [B, N, 20]\n",
    "        S_true: True sequence [B, N]\n",
    "        mask: Valid positions [B, N]\n",
    "    \n",
    "    Returns:\n",
    "        loss: Scalar loss value\n",
    "        perplexity: Perplexity metric\n",
    "    \"\"\"\n",
    "    criterion = nn.NLLLoss(reduction='none')\n",
    "    \n",
    "    # Compute loss per position\n",
    "    loss = criterion(\n",
    "        log_probs.contiguous().view(-1, 20),\n",
    "        S_true.contiguous().view(-1)\n",
    "    ).view(S_true.size())\n",
    "    \n",
    "    # Mask invalid positions\n",
    "    loss = loss * mask\n",
    "    \n",
    "    # Average over valid positions\n",
    "    loss_avg = loss.sum() / mask.sum()\n",
    "    \n",
    "    # Compute perplexity\n",
    "    perplexity = torch.exp(loss_avg)\n",
    "    \n",
    "    return loss_avg, perplexity\n",
    "\n",
    "# Test loss computation\n",
    "loss, perplexity = compute_loss(log_probs, S_test, mask_test)\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "print(f\"Perplexity: {perplexity.item():.4f}\")\n",
    "print(f\"\\nPerplexity interpretation:\")\n",
    "print(f\"- Random baseline: 20.0 (uniform over 20 amino acids)\")\n",
    "print(f\"- Good model: 4-7\")\n",
    "print(f\"- Perfect model: 1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step_example(model, X, S, mask, optimizer):\n",
    "    \"\"\"\n",
    "    Example training step.\n",
    "    \n",
    "    In practice, you would:\n",
    "    1. Load batches from DataLoader\n",
    "    2. Repeat for many epochs\n",
    "    3. Validate on held-out set\n",
    "    4. Save best model\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    log_probs = model(X, S, mask)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss, perplexity = compute_loss(log_probs, S, mask)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), perplexity.item()\n",
    "\n",
    "# Example: one training step\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss, perplexity = training_step_example(model, X_test, S_test, mask_test, optimizer)\n",
    "print(f\"After one training step:\")\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Perplexity: {perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Generation (Sampling)\n",
    "\n",
    "To design new sequences, we sample from the model autoregressively:\n",
    "\n",
    "```python\n",
    "for i in range(n_residues):\n",
    "    # Get probabilities for position i\n",
    "    probs = model.predict_position(i, structure, sequence[:i])\n",
    "    \n",
    "    # Sample amino acid\n",
    "    aa = sample(probs, temperature)\n",
    "    \n",
    "    # Add to sequence\n",
    "    sequence[i] = aa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequence(model, X, mask, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Sample a protein sequence for a given structure.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Struct2Seq model\n",
    "        X: Structure coordinates [B, N, 4, 3]\n",
    "        mask: Valid residues [B, N]\n",
    "        temperature: Sampling temperature (higher = more random)\n",
    "    \n",
    "    Returns:\n",
    "        S: Sampled sequence [B, N]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    batch_size = X.size(0)\n",
    "    n_residues = X.size(1)\n",
    "    \n",
    "    # Initialize empty sequence\n",
    "    S = torch.zeros(batch_size, n_residues, dtype=torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Featurize structure (done once)\n",
    "        V, E, E_idx = model.features(X, mask)\n",
    "        h_V_encoder = model.W_v(V)\n",
    "        h_E = model.W_e(E)\n",
    "        \n",
    "        # Encode structure\n",
    "        mask_attend = gather_nodes(mask.unsqueeze(-1), E_idx).squeeze(-1)\n",
    "        mask_attend = mask.unsqueeze(-1) * mask_attend\n",
    "        \n",
    "        for layer in model.encoder_layers:\n",
    "            h_EV = cat_neighbors_nodes(h_V_encoder, h_E, E_idx)\n",
    "            h_V_encoder = layer(h_V_encoder, h_EV, mask_V=mask, \n",
    "                               mask_attend=mask_attend)\n",
    "        \n",
    "        # Sample sequence position by position\n",
    "        h_S = torch.zeros_like(h_V_encoder)\n",
    "        \n",
    "        for t in range(n_residues):\n",
    "            # Update sequence embedding up to position t\n",
    "            h_S_t = model.W_s(S[:, :t+1])\n",
    "            h_S[:, :t+1, :] = h_S_t\n",
    "            \n",
    "            # Decode\n",
    "            h_V = h_V_encoder.clone()\n",
    "            h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)\n",
    "            h_ES_encoder = cat_neighbors_nodes(torch.zeros_like(h_S), h_E, E_idx)\n",
    "            h_ESV_encoder = cat_neighbors_nodes(h_V_encoder, h_ES_encoder, E_idx)\n",
    "            \n",
    "            mask_ar = model._autoregressive_mask(E_idx).unsqueeze(-1)\n",
    "            mask_1D = mask.view(mask.size(0), mask.size(1), 1, 1)\n",
    "            mask_bw = mask_1D * mask_ar\n",
    "            mask_fw = mask_1D * (1 - mask_ar)\n",
    "            h_ESV_encoder_fw = mask_fw * h_ESV_encoder\n",
    "            \n",
    "            for layer in model.decoder_layers:\n",
    "                h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n",
    "                h_ESV = mask_bw * h_ESV + h_ESV_encoder_fw\n",
    "                h_V = layer(h_V, h_ESV, mask_V=mask)\n",
    "            \n",
    "            # Predict position t\n",
    "            logits_t = model.W_out(h_V[:, t, :])\n",
    "            probs_t = F.softmax(logits_t / temperature, dim=-1)\n",
    "            \n",
    "            # Sample\n",
    "            S[:, t] = torch.multinomial(probs_t, 1).squeeze(-1)\n",
    "    \n",
    "    return S\n",
    "\n",
    "# Example: Sample a sequence\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "\n",
    "with torch.no_grad():\n",
    "    S_sampled = sample_sequence(model, X_test[:1], mask_test[:1], temperature=1.0)\n",
    "\n",
    "# Convert to string\n",
    "seq_str = ''.join([amino_acids[s] for s in S_sampled[0]])\n",
    "print(f\"Sampled sequence: {seq_str}\")\n",
    "print(f\"\\nNote: This is from an untrained model, so it's random!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Sampling\n",
    "\n",
    "**Temperature** controls randomness:\n",
    "\n",
    "```\n",
    "probs = softmax(logits / T)\n",
    "```\n",
    "\n",
    "- **T = 0.1**: Very confident (argmax)\n",
    "- **T = 1.0**: Normal sampling\n",
    "- **T = 2.0**: More random/diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_temperature():\n",
    "    \"\"\"Show effect of temperature on sampling.\"\"\"\n",
    "    # Create example logits\n",
    "    logits = torch.tensor([2.0, 1.0, 0.5, 0.3, 0.1])\n",
    "    \n",
    "    temperatures = [0.1, 0.5, 1.0, 2.0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i, T in enumerate(temperatures):\n",
    "        probs = F.softmax(logits / T, dim=0)\n",
    "        \n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.bar(range(5), probs.numpy())\n",
    "        plt.title(f'Temperature = {T}')\n",
    "        plt.xlabel('Amino Acid')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "demonstrate_temperature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "**What we learned:**\n",
    "\n",
    "1. **Protein Representation**\n",
    "   - Proteins as graphs with nodes (residues) and edges (spatial neighbors)\n",
    "   - Features: distances, angles, orientations\n",
    "\n",
    "2. **Model Architecture**\n",
    "   - **Encoder**: Process structure with unmasked attention\n",
    "   - **Decoder**: Generate sequence with autoregressive masking\n",
    "   - **Attention**: Aggregate information from neighbors adaptively\n",
    "\n",
    "3. **Key Components**\n",
    "   - k-NN graph construction\n",
    "   - RBF and positional encodings\n",
    "   - Multi-head attention\n",
    "   - Transformer layers with residual connections\n",
    "   - Autoregressive generation\n",
    "\n",
    "4. **Training and Inference**\n",
    "   - Loss: Negative log-likelihood\n",
    "   - Metric: Perplexity\n",
    "   - Sampling: Temperature-controlled generation\n",
    "\n",
    "**Next Steps:**\n",
    "1. Train on real protein data\n",
    "2. Evaluate on test structures\n",
    "3. Generate diverse sequences\n",
    "4. Validate designs experimentally\n",
    "\n",
    "**References:**\n",
    "- Paper: Ingraham et al., NeurIPS 2019\n",
    "- Code: `struct2seq/` directory\n",
    "- Tutorial: TUTORIAL.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises\n",
    "\n",
    "**Try these to deepen your understanding:**\n",
    "\n",
    "1. **Modify k in k-NN graph**\n",
    "   - How does changing k affect the graph connectivity?\n",
    "   - Plot connectivity matrices for k=5, 10, 20, 30\n",
    "\n",
    "2. **Visualize attention weights**\n",
    "   - Extract attention weights during forward pass\n",
    "   - Visualize which residues attend to which\n",
    "   - Compare different attention heads\n",
    "\n",
    "3. **Implement MPNN variant**\n",
    "   - Replace TransformerLayer with MPNNLayer\n",
    "   - Compare performance\n",
    "\n",
    "4. **Sequence recovery analysis**\n",
    "   - Load real protein structure\n",
    "   - Generate sequences\n",
    "   - Compute % recovery vs native\n",
    "\n",
    "5. **Feature ablation study**\n",
    "   - Remove different features (RBF, dihedrals, etc.)\n",
    "   - Measure impact on perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Additional Resources\n",
    "\n",
    "**Papers:**\n",
    "- Ingraham et al., \"Generative Models for Graph-Based Protein Design\" (NeurIPS 2019)\n",
    "- Vaswani et al., \"Attention Is All You Need\" (NeurIPS 2017)\n",
    "- Gilmer et al., \"Neural Message Passing for Quantum Chemistry\" (ICML 2017)\n",
    "\n",
    "**Code:**\n",
    "- `struct2seq/struct2seq.py` - Complete model implementation\n",
    "- `struct2seq/protein_features.py` - Full featurization code\n",
    "- `struct2seq/self_attention.py` - Attention mechanisms\n",
    "- `experiments/train_s2s.py` - Training script\n",
    "\n",
    "**Datasets:**\n",
    "- CATH: Protein structure classification\n",
    "- SPIN2: Short protein sequences benchmark\n",
    "\n",
    "**Tools:**\n",
    "- PyTorch: Deep learning framework\n",
    "- PyMOL: Protein visualization\n",
    "- BioPython: Protein structure parsing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
